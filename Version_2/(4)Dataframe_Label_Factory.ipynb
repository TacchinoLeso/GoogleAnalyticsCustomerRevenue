{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Random seed for reproducibility\n",
    "seed = 202\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Garbage collector\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1708337, 37), (401589, 37))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the preprocessed dataframes\n",
    "train_raw_df = pd.read_csv(\"(3)preprocessed_train.csv\",\n",
    "    dtype={'fullVisitorId': str}, nrows=None)\n",
    "test_raw_df = pd.read_csv(\"(3)preprocessed_test.csv\",\n",
    "    dtype={'fullVisitorId': str}, nrows=None)\n",
    "train_raw_df.shape, test_raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the date from VisitStartTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(df):\n",
    "    df['full_date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n",
    "    df['date'] = df['full_date'].dt.date\n",
    "    df.drop(['full_date'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1708337, 38), (401589, 38))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = extract_date(train_raw_df)\n",
    "test_df = extract_date(test_raw_df)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate train and test to extract the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2109926, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df = pd.concat([train_df, test_df])\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe containing only couples of fullvisitorid and totaltransactionrevenue when the latter is not null\n",
    "def zip_df_on_revenue(df):\n",
    "    fullID = []\n",
    "    not_null_transactions = []\n",
    "    for row in df.itertuples():\n",
    "        if(row.totals_transactionRevenue > 0):\n",
    "            fullID.append(row.fullVisitorId)\n",
    "            not_null_transactions.append(row.totals_transactionRevenue)\n",
    "    temp_df = pd.DataFrame({'fullVisitorId': fullID})\n",
    "    not_null_transactions_temp_df = pd.DataFrame({'totals_transactionRevenue': not_null_transactions})\n",
    "    temp_df = temp_df.join(not_null_transactions_temp_df)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label(df, id_label):\n",
    "    label = []\n",
    "\n",
    "    for user in df['fullVisitorId'].values:\n",
    "        temp = 0\n",
    "        if(user in id_label.fullVisitorId.values):\n",
    "            for record in id_label.itertuples():\n",
    "                if (record.fullVisitorId == user):\n",
    "                    temp += record.totals_transactionRevenue\n",
    "        label.append(temp)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window version (no overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first date in the train set is 2016-08-01\n",
      "The last date in the train set is 2018-05-01\n",
      "Thus we have an amount of days in the train set equal to 639 days\n"
     ]
    }
   ],
   "source": [
    "train_start_date = min(train_df.date)\n",
    "train_end_date = max(train_df.date)\n",
    "\n",
    "train_span = (train_end_date - train_start_date).days + 1\n",
    "\n",
    "print(\"The first date in the train set is %s\" % train_start_date)\n",
    "print(\"The last date in the train set is %s\" % train_end_date)\n",
    "print(\"Thus we have an amount of days in the train set equal to %d days\" % train_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first date in the test set is 2018-05-01\n",
      "The last date in the test set is 2018-10-16\n",
      "Thus we have an amount of days in the test set equal to 168 days\n"
     ]
    }
   ],
   "source": [
    "test_start_date = min(test_df.date)\n",
    "test_end_date = max(test_df.date)\n",
    "\n",
    "test_span = (test_end_date - test_start_date).days\n",
    "\n",
    "print(\"The first date in the test set is %s\" % test_start_date)\n",
    "print(\"The last date in the test set is %s\" % test_end_date)\n",
    "print(\"Thus we have an amount of days in the test set equal to %d days\" % test_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have to predict the sum of the transactionRevenue, for each user in the period between 2018-05-01 and 2018-10-16, in the period that goes from 2018-12-01 to 2019-01-31\n",
      "There is a gap of 46 days between the last day of our dataset and the prediction\n",
      "We have to predict 61 days after this gap\n"
     ]
    }
   ],
   "source": [
    "test_label_start_date = pd.to_datetime(\"2018-12-01\").date()\n",
    "test_label_end_date = pd.to_datetime(\"2019-01-31\").date()\n",
    "\n",
    "missing_days = (test_label_start_date - test_end_date).days\n",
    "prediction_span = (test_label_end_date - test_label_start_date).days\n",
    "\n",
    "print(\"We have to predict the sum of the transactionRevenue, for each user in the period between %s and %s, in the period that goes from %s to %s\" % (test_start_date, test_end_date, test_label_start_date, test_label_end_date))\n",
    "print(\"There is a gap of %d days between the last day of our dataset and the prediction\" % missing_days)\n",
    "print(\"We have to predict %d days after this gap\" % prediction_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the periods for both the train and the train's label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first split goes from 2016-08-01 to 2016-11-12 (103 days)\n",
      "The first split label goes from 2016-12-28 to 2017-02-27 (61 days)\n"
     ]
    }
   ],
   "source": [
    "first_split_start = train_start_date\n",
    "first_split_end = pd.to_datetime(\"2016-11-12\").date()\n",
    "first_split_span = (first_split_end - first_split_start).days\n",
    "\n",
    "first_split_label_start = first_split_end + datetime.timedelta(missing_days)\n",
    "first_split_label_end = first_split_label_start + datetime.timedelta(prediction_span)\n",
    "\n",
    "print(\"The first split goes from %s to %s (%d days)\" % (first_split_start, first_split_end, first_split_span))\n",
    "print(\"The first split label goes from %s to %s (%d days)\" % (first_split_label_start, first_split_label_end, (first_split_label_end - first_split_label_start).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second split goes from 2016-11-13 to 2017-04-30 (168 days)\n",
      "The second split label goes from 2017-06-15 to 2017-08-15 (61 days)\n"
     ]
    }
   ],
   "source": [
    "second_split_start = first_split_end + datetime.timedelta(days = 1)\n",
    "second_split_end = second_split_start + datetime.timedelta(days = test_span)\n",
    "second_split_span = (second_split_end - second_split_start).days\n",
    "\n",
    "second_split_label_start = second_split_end + datetime.timedelta(missing_days)\n",
    "second_split_label_end = second_split_label_start + datetime.timedelta(prediction_span)\n",
    "\n",
    "print(\"The second split goes from %s to %s (%d days)\" % (second_split_start, second_split_end, second_split_span))\n",
    "print(\"The second split label goes from %s to %s (%d days)\" % (second_split_label_start, second_split_label_end, (second_split_label_end - second_split_label_start).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third period (exacltly one year of difference from the request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third split goes from 2017-05-01 to 2017-10-16 (168 days)\n",
      "The third split label goes from 2017-12-01 to 2018-01-31 (61 days)\n"
     ]
    }
   ],
   "source": [
    "third_split_start = second_split_end + datetime.timedelta(days = 1)\n",
    "third_split_end = third_split_start + datetime.timedelta(days = test_span)\n",
    "third_split_span = (third_split_end - third_split_start).days\n",
    "\n",
    "third_split_label_start = third_split_end + datetime.timedelta(missing_days)\n",
    "third_split_label_end = third_split_label_start + datetime.timedelta(prediction_span)\n",
    "\n",
    "print(\"The third split goes from %s to %s (%d days)\" % (third_split_start, third_split_end, third_split_span))\n",
    "print(\"The third split label goes from %s to %s (%d days)\" % (third_split_label_start, third_split_label_end, (third_split_label_end - third_split_label_start).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fourth split goes from 2017-10-17 to 2018-04-03 (168 days)\n",
      "The fourth split label goes from 2018-05-19 to 2018-07-19 (61 days)\n"
     ]
    }
   ],
   "source": [
    "fourth_split_start = third_split_end + datetime.timedelta(days = 1)\n",
    "fourth_split_end = fourth_split_start + datetime.timedelta(days = test_span)\n",
    "fourth_split_span = (fourth_split_end - fourth_split_start).days\n",
    "\n",
    "fourth_split_label_start = fourth_split_end + datetime.timedelta(missing_days)\n",
    "fourth_split_label_end = fourth_split_label_start + datetime.timedelta(prediction_span)\n",
    "\n",
    "print(\"The fourth split goes from %s to %s (%d days)\" % (fourth_split_start, fourth_split_end, fourth_split_span))\n",
    "print(\"The fourth split label goes from %s to %s (%d days)\" % (fourth_split_label_start, fourth_split_label_end, (fourth_split_label_end - fourth_split_label_start).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fifth period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fifth split goes from 2018-04-04 to 2018-04-30 (26 days)\n",
      "The fifth split label goes from 2018-06-15 to 2018-08-15 (61 days)\n"
     ]
    }
   ],
   "source": [
    "fifth_split_start = fourth_split_end + datetime.timedelta(days = 1)\n",
    "fifth_split_end = train_end_date - datetime.timedelta(days = 1)\n",
    "fifth_split_span = (fifth_split_end - fifth_split_start).days\n",
    "\n",
    "fifth_split_label_start = fifth_split_end + datetime.timedelta(missing_days)\n",
    "fifth_split_label_end = fifth_split_label_start + datetime.timedelta(prediction_span)\n",
    "\n",
    "print(\"The fifth split goes from %s to %s (%d days)\" % (fifth_split_start, fifth_split_end, fifth_split_span))\n",
    "print(\"The fifth split label goes from %s to %s (%d days)\" % (fifth_split_label_start, fifth_split_label_end, (fifth_split_label_end - fifth_split_label_start).days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data for both the train and the train's label (this one, from the total dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2016-08-01 to 2016-11-12\n",
      "Label from 2016-12-28 to 2017-02-27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((286306, 38), (130267, 38))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_labeled_train = train_df[(train_df['date'].values <= first_split_end) & (train_df['date'].values >= first_split_start)]\n",
    "first_temp_train_label = total_df[(total_df['date'].values <= first_split_label_end) & (total_df['date'].values >= first_split_label_start)]\n",
    "\n",
    "print(\"Data %s to %s\" % (min(first_labeled_train.date), max(first_labeled_train.date)))\n",
    "print(\"Label from %s to %s\" % (min(first_temp_train_label.date), max(first_temp_train_label.date)))\n",
    "first_labeled_train.shape, first_temp_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2016-11-13 to 2017-04-30\n",
      "Label from 2017-06-15 to 2017-08-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((413571, 38), (145838, 38))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_labeled_train = train_df[(train_df['date'].values <= second_split_end) & (train_df['date'].values >= second_split_start)]\n",
    "second_temp_train_label = total_df[(total_df['date'].values <= second_split_label_end) & (total_df['date'].values >= second_split_label_start)]\n",
    "\n",
    "print(\"Data %s to %s\" % (min(second_labeled_train.date), max(second_labeled_train.date)))\n",
    "print(\"Label from %s to %s\" % (min(second_temp_train_label.date), max(second_temp_train_label.date)))\n",
    "second_labeled_train.shape, second_temp_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2017-05-01 to 2017-10-16\n",
      "Label from 2017-12-01 to 2018-01-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((427826, 38), (180572, 38))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_labeled_train = train_df[(train_df['date'].values <= third_split_end) & (train_df['date'].values >= third_split_start)]\n",
    "third_temp_train_label = total_df[(total_df['date'].values <= third_split_label_end) & (total_df['date'].values >= third_split_label_start)]\n",
    "\n",
    "print(\"Data %s to %s\" % (min(third_labeled_train.date), max(third_labeled_train.date)))\n",
    "print(\"Label from %s to %s\" % (min(third_temp_train_label.date), max(third_temp_train_label.date)))\n",
    "third_labeled_train.shape, third_temp_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2017-10-17 to 2018-04-03\n",
      "Label from 2018-05-19 to 2018-07-19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((505866, 38), (150761, 38))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_labeled_train = train_df[(train_df['date'].values <= fourth_split_end) & (train_df['date'].values >= fourth_split_start)]\n",
    "fourth_temp_train_label = total_df[(total_df['date'].values <= fourth_split_label_end) & (total_df['date'].values >= fourth_split_label_start)]\n",
    "\n",
    "print(\"Data %s to %s\" % (min(fourth_labeled_train.date), max(fourth_labeled_train.date)))\n",
    "print(\"Label from %s to %s\" % (min(fourth_temp_train_label.date), max(fourth_temp_train_label.date)))\n",
    "fourth_labeled_train.shape, fourth_temp_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fifth data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 2018-04-04 to 2018-04-30\n",
      "Label from 2018-06-15 to 2018-08-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((74126, 38), (139432, 38))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifth_labeled_train = train_df[(train_df['date'].values <= fifth_split_end) & (train_df['date'].values >= fifth_split_start)]\n",
    "fifth_temp_train_label = total_df[(total_df['date'].values <= fifth_split_label_end) & (total_df['date'].values >= fifth_split_label_start)]\n",
    "\n",
    "print(\"Data %s to %s\" % (min(fifth_labeled_train.date), max(fifth_labeled_train.date)))\n",
    "print(\"Label from %s to %s\" % (min(fifth_temp_train_label.date), max(fifth_temp_train_label.date)))\n",
    "fifth_labeled_train.shape, fifth_temp_train_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the label for each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_list = []\n",
    "labeled_train_list.append(first_labeled_train)\n",
    "labeled_train_list.append(second_labeled_train)\n",
    "labeled_train_list.append(third_labeled_train)\n",
    "labeled_train_list.append(fourth_labeled_train)\n",
    "labeled_train_list.append(fifth_labeled_train)\n",
    "\n",
    "zipped_label_list = []\n",
    "zipped_label_list.append(zip_df_on_revenue(first_temp_train_label))\n",
    "zipped_label_list.append(zip_df_on_revenue(second_temp_train_label))\n",
    "zipped_label_list.append(zip_df_on_revenue(third_temp_train_label))\n",
    "zipped_label_list.append(zip_df_on_revenue(fourth_temp_train_label))\n",
    "zipped_label_list.append(zip_df_on_revenue(fifth_temp_train_label))\n",
    "\n",
    "labels = []\n",
    "for i in range(0, len(labeled_train_list)):\n",
    "    labels.append(compute_label(labeled_train_list[i],zipped_label_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the indices to merge data and labels\n",
    "for i in range(0,len(labeled_train_list)):\n",
    "    temp_label = np.nan\n",
    "    labeled_train_list[i] = labeled_train_list[i].reset_index(drop=True) # Important\n",
    "    \n",
    "    temp_label = pd.DataFrame({'label': labels[i]})\n",
    "    temp_label = temp_label.reset_index(drop=True) # Important!\n",
    "    \n",
    "    labeled_train_list[i] = labeled_train_list[i].join(temp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15990000.0\n",
       "1           0.0\n",
       "2           0.0\n",
       "3           0.0\n",
       "4           0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_train_list[2].label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15990000.0\n",
      "15990000.0\n",
      "15990000.0\n",
      "15990000.0\n",
      "15990000.0\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "for i in labeled_train_list[2].itertuples():\n",
    "    if i.fullVisitorId == '8934116514970143966':\n",
    "        print(i.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reconstruction is happended succesfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1707695, 39)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_train_df = pd.concat([labeled_train_list[0], labeled_train_list[1], labeled_train_list[2], labeled_train_list[3], labeled_train_list[4]])\n",
    "labeled_train_df = labeled_train_df.reset_index(drop=True)\n",
    "# Size check\n",
    "dropped_records = (train_df.date >= pd.to_datetime(\"2018-05-01\").date()).sum()\n",
    "if(labeled_train_df.shape[0] + dropped_records == train_df.shape[0]):\n",
    "    print(\"The reconstruction is happended succesfully!\")\n",
    "labeled_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### maybe we can delete date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_train_df.to_csv('(4)labeled_train.csv', index = False)\n",
    "test_df.to_csv('(4)labeled_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
