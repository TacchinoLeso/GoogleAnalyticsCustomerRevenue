{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "173b76b89cfc565e621e59651e60d3071b3ae3b1"
   },
   "source": [
    "<h1>Customer Revenue Prediction</h1>\n",
    "Reference:<br>\n",
    "https://www.kaggle.com/plasticgrammer/customer-revenue-prediction-v2-playground<br>\n",
    "https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4e9cb223c406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "print(os.listdir(\"../../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e5e5499bde22d1ea27fe31fffe7a5f7c8f9f11a"
   },
   "outputs": [],
   "source": [
    "features = ['channelGrouping', 'date', 'fullVisitorId', 'visitId',\\\n",
    "       'visitNumber', 'visitStartTime', 'device.operatingSystem',\\\n",
    "       'geoNetwork.city', 'geoNetwork.country','geoNetwork.metro',\\\n",
    "       'geoNetwork.networkDomain', 'geoNetwork.region', 'totals.hits',\\\n",
    "       'totals.pageviews', 'totals.transactionRevenue', 'trafficSource.adContent',\\\n",
    "       'trafficSource.isTrueDirect', 'trafficSource.referralPath', 'trafficSource.source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#DataIterator for batch learning\n",
    "class DataIterator():\n",
    "    def __init__(self, filePath='../input/train_v2.csv'):\n",
    "        self.JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "        self.iter = pd.read_csv(filePath, converters={column: json.loads for column in self.JSON_COLUMNS}, dtype={'fullVisitorId': 'str'}, iterator=True)\n",
    "\n",
    "        print(f'Loaded {os.path.basename (filePath)}.')\n",
    "    \n",
    "    def getChunk(self, chunkSize):\n",
    "        df = self.iter.get_chunk(chunkSize)\n",
    "\n",
    "        for column in self.JSON_COLUMNS:\n",
    "            column_as_df = json_normalize(df[column])\n",
    "            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "            column_as_df.index = df.index\n",
    "            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "        df['totals.transactionRevenue'].fillna(0, inplace=True)\n",
    "        df['totals.transactionRevenue'] = np.log1p(df['totals.transactionRevenue'].astype(float))\n",
    "            \n",
    "        # fillna object feature\n",
    "        for col in ['trafficSource.keyword',\n",
    "                    'trafficSource.referralPath',\n",
    "                    'trafficSource.adContent']:\n",
    "            df[col].fillna('unknown', inplace=True)\n",
    "\n",
    "        # fillna numeric feature\n",
    "        df['totals.pageviews'].fillna(1, inplace=True)\n",
    "        df['totals.newVisits'].fillna(0, inplace=True)\n",
    "        df['totals.bounces'].fillna(0, inplace=True)\n",
    "        df['totals.pageviews'] = df['totals.pageviews'].astype(int)\n",
    "        df['totals.newVisits'] = df['totals.newVisits'].astype(int)\n",
    "        df['totals.bounces'] = df['totals.bounces'].astype(int)\n",
    "\n",
    "        # fillna boolean feature\n",
    "        df['trafficSource.isTrueDirect'].fillna(False, inplace=True)\n",
    "        \n",
    "        df = df[features]\n",
    "        \n",
    "        \n",
    "        format_str = '%Y%m%d'\n",
    "        df['formated_date'] = df['date'].apply(lambda x: datetime.strptime(str(x), format_str))\n",
    "        df['_month'] = df['formated_date'].apply(lambda x:x.month)\n",
    "        df['_day'] = df['formated_date'].apply(lambda x:x.day)\n",
    "        df.drop(['date','formated_date'], axis=1, inplace=True)\n",
    "        \n",
    "        df.drop(['visitId'],axis=1,inplace=True)\n",
    "\n",
    "        for i, t in df.loc[:, df.columns != 'fullVisitorId'].dtypes.iteritems():\n",
    "            if t == object:\n",
    "                df[i].fillna('unknown', inplace=True)\n",
    "                df[i] = pd.factorize(df[i])[0]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81d370d607ed7a7313e4b548fdfe89879c20f4fd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = DataIterator()\n",
    "train = train_data.getChunk(100000)\n",
    "test_data = DataIterator('../input/test_v2.csv')\n",
    "test = test_data.getChunk(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9671e1182e94d20d7f9f87ae661c506afadc385",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_id = train['fullVisitorId']\n",
    "test_id = test['fullVisitorId']\n",
    "\n",
    "Y_train = train.pop('totals.transactionRevenue')\n",
    "Y_test = test.pop('totals.transactionRevenue')\n",
    "X_train = train.drop(['fullVisitorId'], axis=1)\n",
    "X_test  = test.drop(['fullVisitorId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "638636d37cc0c68484c5a798412b7f944c0c9d05"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "805cf352c3a2940b2e2ffbba34122ac342fddd88"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "496fc31e6cda803471681636ee087bfce5d4a016",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params={'learning_rate': 0.01,\n",
    "        'objective':'regression',\n",
    "        'metric':'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'verbose': 1,\n",
    "        'random_state':42,\n",
    "        'bagging_fraction': 0.6,\n",
    "        'feature_fraction': 0.6\n",
    "       }\n",
    "\n",
    "folds = GroupKFold(n_splits=5)\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(X_train, Y_train, groups=train_id)):\n",
    "    trn_x, trn_y = X_train.iloc[trn_], Y_train.iloc[trn_]\n",
    "    val_x, val_y = X_train.iloc[val_], Y_train.iloc[val_]\n",
    "    \n",
    "    reg = lgb.LGBMRegressor(**params, n_estimators=3000)\n",
    "    #reg = SGDRegressor()\n",
    "    reg.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=50, verbose=500)\n",
    "    #reg.partial_fit(trn_x, trn_y)\n",
    "    \n",
    "    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n",
    "    #oof_preds[val_] = reg.predict(val_x)\n",
    "    sub_preds += reg.predict(X_test, num_iteration=reg.best_iteration_) / folds.n_splits\n",
    "    #sub_preds = reg.predict(X_test)\n",
    "\n",
    "pred = sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d5437c311e6e4ae5ad45f20ee28fada9fcc5049"
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_importance = reg.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "sorted_idx = sorted_idx[len(feature_importance) - 30:]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_train.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2e4628c434989d39817b363fd2fafa2fe046286",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'fullVisitorId':test_id, 'PredictedLogRevenue':pred})\n",
    "\n",
    "submission[\"PredictedLogRevenue\"] = np.expm1(submission[\"PredictedLogRevenue\"])\n",
    "submission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].apply(lambda x : 0.0 if x < 0 else x)\n",
    "submission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].fillna(0.0)\n",
    "\n",
    "submission_sum = submission[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\n",
    "submission_sum[\"PredictedLogRevenue\"] = np.log1p(submission_sum[\"PredictedLogRevenue\"])\n",
    "submission_sum.to_csv(\"submission.csv\", index=False)\n",
    "submission_sum.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e11ad7780b54475d722b970c3bb44ebc7992f96"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
